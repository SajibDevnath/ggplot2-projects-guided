[
  {
    "path": "posts/2020-12-21-project-10/",
    "title": "Project 10",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-21",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\nbb <- read_csv(here::here(\"data\", \"bb_chords.csv\"))\r\n\r\n\r\n\r\nThe most common chords:\r\n\r\n\r\nbb_count <- bb %>% \r\n  count(chord, sort = TRUE)\r\n\r\n\r\n\r\n\r\n\r\nbb_count %>% \r\n  slice(1:20) %>% \r\n  mutate(\r\n    share = n / sum(n),\r\n    chord = reorder(chord, n)\r\n  ) %>% \r\n  ggplot(aes(chord, share, fill = chord)) +\r\n  geom_col() +\r\n  coord_flip() +\r\n  labs(\r\n    y = \"Share of total chords\",\r\n    x = \"chord\"\r\n  ) +\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nChord “bigrams”\r\n\r\n\r\nbb_bigram_count <- bb %>% \r\n  mutate(next_chord = lead(chord),\r\n         next_title = lead(title)) %>%\r\n  filter(title == next_title) %>% \r\n  mutate(bigram = paste(chord, next_chord)) %>% \r\n  count(bigram, sort = TRUE)\r\n\r\n\r\n\r\n\r\n\r\nbb_bigram_count %>% \r\n  slice(1:20) %>% \r\n  mutate(\r\n    share = n / sum(n),\r\n    bigram = reorder(bigram, n)\r\n  ) %>% \r\n  ggplot(aes(bigram, share, fill = bigram)) +\r\n  geom_col() +\r\n  coord_flip() +\r\n  labs(\r\n    y = \"Share of total bigram\",\r\n    x = \"bigram\"\r\n  ) +\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nMost common artists:\r\n\r\n\r\nbb_30_artists <- bb %>%\r\n  select(artist, title) %>%\r\n  unique() %>%\r\n  count(artist, sort = TRUE)\r\n\r\nbb_30_artists %>%\r\n  slice(1:30)\r\n\r\n\r\n# A tibble: 30 x 2\r\n   artist            n\r\n   <chr>         <int>\r\n 1 Elvis Presley    13\r\n 2 Brenda Lee        9\r\n 3 Dion              8\r\n 4 Bob Seger         7\r\n 5 James Brown       7\r\n 6 Kenny Rogers      7\r\n 7 The Beatles       7\r\n 8 Chicago           6\r\n 9 Dr. Hook          6\r\n10 Eric Clapton      6\r\n# ... with 20 more rows\r\n\r\n\r\n\r\ntags <- tibble(\r\n  artist = c('Abba', 'Billy Joel', 'Elton John', 'Stevie Wonder', 'The Rolling Stones', 'The Beatles', 'Eric Clapton'),\r\n  instrument = c('piano', 'piano', 'piano', 'piano', 'guitar', 'guitar', 'guitar'))\r\n\r\nbb_tagged <- bb %>% \r\n  inner_join(tags, by = \"artist\")\r\n\r\n\r\n\r\n\r\n\r\ntop_20 <- bb_count$chord[1:20]\r\n\r\n\r\nbb_tagged %>%\r\n  filter(chord %in% top_20) %>%\r\n  count(chord, instrument, sort = TRUE) %>%\r\n  ggplot(aes(reorder(chord, n), n, fill = chord)) +\r\n  geom_col() +\r\n  facet_grid(~ instrument) +\r\n  coord_flip() +\r\n  xlab(\"Chord\") +\r\n  ylab(\"Number of times used\") +\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\n\r\n\r\ntop_20_bigram <- bb_bigram_count$bigram[1:20]\r\n\r\nbb_tagged %>%\r\n  mutate(next_chord = lead(chord),\r\n         next_title = lead(title),\r\n         bigram = paste(chord, next_chord)) %>%\r\n  filter(title == next_title) %>%\r\n  count(bigram, instrument, sort = TRUE) %>%\r\n  filter(bigram %in% top_20_bigram) %>%\r\n  ggplot(aes(bigram, n, fill = bigram)) +\r\n  geom_col() +\r\n  facet_grid(~instrument) +\r\n  coord_flip() +\r\n  ylab('Total bigrams') +\r\n  xlab('Bigram') +\r\n  theme(legend.position=\"none\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-21-project-10/project-10_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-21T12:26:55+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-21-project-11/",
    "title": "Project 11",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-21",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\nlibrary(patchwork)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\nbottom <- read_csv(here::here(\"data\", \"bottom_line.csv\"),\r\n                   col_types = cols(Ping_date = col_datetime(format = \"%m/%d/%Y\"))) %>% \r\n  rename_all(tolower)\r\n\r\nglimpse(bottom)\r\n\r\n\r\nRows: 2,766\r\nColumns: 10\r\n$ ping_date         <dttm> 2011-06-18, 2011-06-18, 2011-06-18, 20...\r\n$ ping_time         <time> 09:53:37, 09:53:42, 09:58:47, 09:58:52...\r\n$ ping_milliseconds <dbl> 725, 741, 866, 866, 866, 866, 882, 882,...\r\n$ latitude          <dbl> 999.00000, 38.29771, 38.29429, 38.29424...\r\n$ longitude         <dbl> 999.00000, -74.00185, -73.99677, -73.99...\r\n$ position_status   <dbl> 4, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\r\n$ depth             <dbl> 68.60377, 68.60024, 68.78515, 68.77859,...\r\n$ line_status       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\r\n$ ping_status       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\r\n$ altitude          <dbl> -9.9e+37, 0.0e+00, 0.0e+00, 0.0e+00, 0....\r\n\r\n\r\n\r\nbottom_clean <- bottom %>% \r\n  filter(position_status == 1) %>% \r\n  select(ping_date, ping_time, latitude, longitude, depth) %>% \r\n  mutate(date_time = ymd_hms(paste(ping_date, ping_time))) %>% \r\n  ## calculate the distance between latitude and longitude along rows of columns\r\n  mutate(\r\n     distance_between = c(\r\n       0, geosphere::distHaversine(cbind(longitude[-n()], latitude[-n()]),\r\n                                                     cbind(longitude[ -1], latitude[ -1]))),                         \r\n       distance_along = cumsum(distance_between)\r\n  )\r\n  \r\nglimpse(bottom_clean)\r\n\r\n\r\nRows: 2,764\r\nColumns: 8\r\n$ ping_date        <dttm> 2011-06-18, 2011-06-18, 2011-06-18, 201...\r\n$ ping_time        <time> 09:58:47, 09:58:52, 09:58:57, 09:59:02,...\r\n$ latitude         <dbl> 38.29429, 38.29424, 38.29418, 38.29411, ...\r\n$ longitude        <dbl> -73.99677, -73.99666, -73.99653, -73.996...\r\n$ depth            <dbl> 68.78515, 68.77859, 68.37986, 68.37986, ...\r\n$ date_time        <dttm> 2011-06-18 09:58:47, 2011-06-18 09:58:5...\r\n$ distance_between <dbl> 0.00000, 11.47956, 12.77948, 13.24406, 1...\r\n$ distance_along   <dbl> 0.00000, 11.47956, 24.25904, 37.50310, 5...\r\n\r\n\r\n\r\np_ship_track <- ggplot(bottom_clean, aes(longitude, latitude)) +\r\n  geom_point(size = .5) +\r\n  labs(x = \"Longitude\", y = \"Latitude\")\r\n\r\np_bathymetry <- ggplot(bottom_clean, aes(distance_along, depth)) +\r\n  geom_point(size = .5) +\r\n  labs(x = \"Distance along trackline (m)\", y = \"Depth (m)\") +\r\n  scale_y_reverse()\r\n\r\np_ship_track + p_bathymetry\r\n\r\n\r\n\r\n\r\n\r\n\r\nacoustic <- read_csv(here::here(\"data\", \"acoustic.csv\"), \r\n                     col_types = cols(Date_M = col_datetime(format = \"%Y%m%d\")))  %>% \r\n  filter(Lon_M != 999.0)\r\n\r\nglimpse(acoustic)\r\n\r\n\r\nRows: 724\r\nColumns: 78\r\n$ Process_ID                           <dbl> 20216, 20216, 20216,...\r\n$ Interval                             <dbl> 4, 5, 6, 7, 8, 9, 10...\r\n$ Layer                                <dbl> 1, 1, 1, 1, 1, 1, 1,...\r\n$ Sv_mean                              <dbl> -67.97805, -67.65053...\r\n$ NASC                                 <dbl> 365.6001, 429.4046, ...\r\n$ Sv_max                               <dbl> -53.93325, -54.51390...\r\n$ Sv_min                               <dbl> -88.67275, -87.36100...\r\n$ Sv_noise                             <dbl> -967.8684, -967.6432...\r\n$ NASC_noise                           <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Height_mean                          <dbl> 53.25000, 58.00000, ...\r\n$ Depth_mean                           <dbl> 39.04617, 39.00000, ...\r\n$ Good_samples                         <dbl> 639, 522, 464, 464, ...\r\n$ Layer_depth_min                      <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Layer_depth_max                      <dbl> 250, 250, 250, 250, ...\r\n$ Ping_S                               <dbl> 2, 14, 23, 31, 39, 4...\r\n$ Ping_E                               <dbl> 13, 22, 30, 38, 45, ...\r\n$ Ping_M                               <dbl> 7, 18, 26, 34, 42, 4...\r\n$ Dist_S                               <dbl> 609.2889, 804.8728, ...\r\n$ Dist_E                               <dbl> 783.8686, 985.7557, ...\r\n$ Dist_M                               <dbl> 676.6425, 891.7338, ...\r\n$ VL_start                             <dbl> 600.4773, 785.7129, ...\r\n$ VL_end                               <dbl> 767.8645, 962.5547, ...\r\n$ VL_mid                               <dbl> 664.4884, 869.5859, ...\r\n$ Date_S                               <dbl> 20110618, 20110618, ...\r\n$ Time_S                               <time> 09:58:47, 09:59:47,...\r\n$ Date_E                               <dbl> 20110618, 20110618, ...\r\n$ Time_E                               <time> 09:59:42, 10:00:27,...\r\n$ Date_M                               <dttm> 2011-06-18, 2011-06...\r\n$ Time_M                               <time> 09:59:12, 10:00:07,...\r\n$ Lat_S                                <dbl> 38.29429, 38.29343, ...\r\n$ Lon_S                                <dbl> -73.99677, -73.99486...\r\n$ Lat_E                                <dbl> 38.29351, 38.29271, ...\r\n$ Lon_E                                <dbl> -73.99506, -73.99301...\r\n$ Lat_M                                <dbl> 38.29396, 38.29309, ...\r\n$ Lon_M                                <dbl> -73.99612, -73.99397...\r\n$ Exclude_below_line_depth_mean        <dbl> 68.43658, 68.25401, ...\r\n$ Alpha                                <dbl> 0.007856, 0.007856, ...\r\n$ Gain_constant                        <dbl> -9999, -9999, -9999,...\r\n$ Noise_Sv_1m                          <dbl> -999, -999, -999, -9...\r\n$ Minimum_Sv_threshold_applied         <dbl> 1, 1, 1, 1, 1, 1, 1,...\r\n$ Minimum_integration_threshold        <dbl> -90, -90, -90, -90, ...\r\n$ Maximum_Sv_threshold_applied         <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Maximum_integration_threshold        <dbl> 99, 99, 99, 99, 99, ...\r\n$ Exclude_above_line_applied           <dbl> 1, 1, 1, 1, 1, 1, 1,...\r\n$ Exclude_above_line_depth_mean        <dbl> 10, 10, 10, 10, 10, ...\r\n$ Exclude_below_line_applied           <dbl> 1, 1, 1, 1, 1, 1, 1,...\r\n$ Bottom_offset                        <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Standard_deviation                   <dbl> 3.67224e-07, 3.45837...\r\n$ Skewness                             <dbl> 6.287088, 5.815767, ...\r\n$ Kurtosis                             <dbl> 50.453991, 45.173827...\r\n$ ABC                                  <dbl> 8.48232e-06, 9.96265...\r\n$ ABC_noise                            <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Area_Backscatter_Strength            <dbl> -50.71486, -50.01625...\r\n$ Thickness_mean                       <dbl> 53.25000, 58.00000, ...\r\n$ Range_mean                           <dbl> 33.04617, 33.00000, ...\r\n$ Exclude_below_line_range_mean        <dbl> 62.43658, 62.25401, ...\r\n$ Exclude_above_line_range_mean        <dbl> 4, 4, 4, 4, 4, 4, 4,...\r\n$ Bad_data_no_data_samples             <dbl> 59, 0, 0, 0, 0, 0, 0...\r\n$ Beam_volume_sum                      <dbl> 7299.070, 5945.382, ...\r\n$ No_data_samples                      <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ C_good_samples                       <dbl> 639, 522, 464, 464, ...\r\n$ C_bad_data_no_data_samples           <dbl> 59, 0, 0, 0, 0, 0, 0...\r\n$ C_no_data_samples                    <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Frequency                            <dbl> 38, 38, 38, 38, 38, ...\r\n$ Grid_reference_line                  <chr> \"\\\"Surface (depth of...\r\n$ Layer_top_to_reference_line_depth    <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ Layer_top_to_reference_line_range    <dbl> -6, -6, -6, -6, -6, ...\r\n$ Layer_bottom_to_reference_line_depth <dbl> 250, 250, 250, 250, ...\r\n$ Layer_bottom_to_reference_line_range <dbl> 244, 244, 244, 244, ...\r\n$ Exclude_below_line_depth_min         <dbl> 68.28604, 68.21009, ...\r\n$ Exclude_below_line_range_min         <dbl> 62.28604, 62.21009, ...\r\n$ Exclude_below_line_depth_max         <dbl> 68.78515, 68.28604, ...\r\n$ Exclude_below_line_range_max         <dbl> 62.78515, 62.28604, ...\r\n$ Samples_Below_Bottom_Exclusion       <dbl> 2182, 1638, 1456, 14...\r\n$ Samples_Above_Surface_Exclusion      <dbl> 48, 36, 32, 32, 28, ...\r\n$ Samples_In_Domain                    <dbl> 2928, 2196, 1952, 19...\r\n$ Bad_data_empty_water_samples         <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n$ C_bad_data_empty_water_samples       <dbl> 0, 0, 0, 0, 0, 0, 0,...\r\n\r\n\r\n\r\nvariables_keep <- c(\"Interval\", \"Layer\", \"Sv_mean\", \"Frequency\", \r\n               \"Date_M\", \"Time_S\", \"Time_E\", \"Lat_M\", \"Lon_M\")\r\n\r\nSv_layer1 <- acoustic %>%\r\n    select(variables_keep) %>% \r\n    rename(Spatial_interval = Interval, Date = Date_M) %>%\r\n    filter(Layer == \"1\")  %>% \r\n    mutate(Datetime_start = Date + Time_S,\r\n           Datetime_end = Date + Time_E)  %>% \r\n    arrange(Datetime_start) \r\n\r\nglimpse(Sv_layer1)\r\n\r\n\r\nRows: 362\r\nColumns: 11\r\n$ Spatial_interval <dbl> 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15...\r\n$ Layer            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\r\n$ Sv_mean          <dbl> -67.97805, -67.65053, -66.65866, -68.244...\r\n$ Frequency        <dbl> 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, ...\r\n$ Date             <dttm> 2011-06-18, 2011-06-18, 2011-06-18, 201...\r\n$ Time_S           <time> 09:58:47, 09:59:47, 10:00:32, 10:01:12,...\r\n$ Time_E           <time> 09:59:42, 10:00:27, 10:01:07, 10:01:47,...\r\n$ Lat_M            <dbl> 38.29396, 38.29309, 38.29230, 38.29147, ...\r\n$ Lon_M            <dbl> -73.99612, -73.99397, -73.99202, -73.989...\r\n$ Datetime_start   <dttm> 2011-06-18 09:58:47, 2011-06-18 09:59:4...\r\n$ Datetime_end     <dttm> 2011-06-18 09:59:42, 2011-06-18 10:00:2...\r\n\r\n\r\n\r\nSv <- Sv_layer1 %>% \r\n  mutate(Distance_between = c(0, geosphere::distHaversine(cbind(Lon_M[-n()], Lat_M[-n()]),       \r\n                                               cbind(Lon_M[  -1], Lat_M[  -1]))),\r\n       Distance_along = cumsum(Distance_between)) %>%\r\n  na_if(-999.0) %>% \r\n  mutate(Time_interval = interval(Datetime_start, Datetime_end))\r\n\r\nglimpse(Sv)\r\n\r\n\r\nRows: 362\r\nColumns: 14\r\n$ Spatial_interval <dbl> 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15...\r\n$ Layer            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\r\n$ Sv_mean          <dbl> -67.97805, -67.65053, -66.65866, -68.244...\r\n$ Frequency        <dbl> 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, ...\r\n$ Date             <dttm> 2011-06-18, 2011-06-18, 2011-06-18, 201...\r\n$ Time_S           <time> 09:58:47, 09:59:47, 10:00:32, 10:01:12,...\r\n$ Time_E           <time> 09:59:42, 10:00:27, 10:01:07, 10:01:47,...\r\n$ Lat_M            <dbl> 38.29396, 38.29309, 38.29230, 38.29147, ...\r\n$ Lon_M            <dbl> -73.99612, -73.99397, -73.99202, -73.989...\r\n$ Datetime_start   <dttm> 2011-06-18 09:58:47, 2011-06-18 09:59:4...\r\n$ Datetime_end     <dttm> 2011-06-18 09:59:42, 2011-06-18 10:00:2...\r\n$ Distance_between <dbl> 0.0000, 211.7871, 192.3324, 204.8778, 20...\r\n$ Distance_along   <dbl> 0.0000, 211.7871, 404.1196, 608.9974, 81...\r\n$ Time_interval    <Interval> 2011-06-18 09:58:47 UTC--2011-06-18...\r\n\r\n\r\n\r\n# Name the function\r\nget_Interval_by_time <- function(bottom_data){\r\n  res <- Sv$Spatial_interval[bottom_data %within% Sv$Time_interval]\r\n  if(length(res)==0) return(NA)         # dealing with NAs\r\n  return(res)\r\n}\r\n \r\n# Map the track line interval value to the bottom_clean data\r\nbottom_spatial_interval_segments <- bottom_clean  %>% \r\n    mutate(trackline_interval = purrr::map_dbl(date_time, get_Interval_by_time))\r\n\r\n# Inspect the first 15 rows\r\nhead(bottom_spatial_interval_segments, 15)\r\n\r\n\r\n# A tibble: 15 x 9\r\n   ping_date           ping_time latitude longitude depth\r\n   <dttm>              <time>       <dbl>     <dbl> <dbl>\r\n 1 2011-06-18 00:00:00 09:58:47      38.3     -74.0  68.8\r\n 2 2011-06-18 00:00:00 09:58:52      38.3     -74.0  68.8\r\n 3 2011-06-18 00:00:00 09:58:57      38.3     -74.0  68.4\r\n 4 2011-06-18 00:00:00 09:59:02      38.3     -74.0  68.4\r\n 5 2011-06-18 00:00:00 09:59:07      38.3     -74.0  68.4\r\n 6 2011-06-18 00:00:00 09:59:12      38.3     -74.0  68.4\r\n 7 2011-06-18 00:00:00 09:59:17      38.3     -74.0  68.4\r\n 8 2011-06-18 00:00:00 09:59:22      38.3     -74.0  68.4\r\n 9 2011-06-18 00:00:00 09:59:27      38.3     -74.0  68.4\r\n10 2011-06-18 00:00:00 09:59:32      38.3     -74.0  68.4\r\n11 2011-06-18 00:00:00 09:59:37      38.3     -74.0  68.3\r\n12 2011-06-18 00:00:00 09:59:42      38.3     -74.0  68.3\r\n13 2011-06-18 00:00:00 09:59:47      38.3     -74.0  68.3\r\n14 2011-06-18 00:00:00 09:59:52      38.3     -74.0  68.3\r\n15 2011-06-18 00:00:00 09:59:57      38.3     -74.0  68.3\r\n# ... with 4 more variables: date_time <dttm>,\r\n#   distance_between <dbl>, distance_along <dbl>,\r\n#   trackline_interval <dbl>\r\n\r\n\r\n\r\n# Group bottom_clean and calculate the mean depth\r\nbottom_intervals <- bottom_spatial_interval_segments %>%\r\n    group_by(trackline_interval) %>%\r\n    summarize(depth_mean = mean(depth)) %>%\r\n    ungroup()\r\n\r\n# Join the bottom intervals data to the acoustic data\r\nSv_and_depth <- Sv %>%\r\n  left_join(bottom_intervals, by = c(\"Spatial_interval\" = \"trackline_interval\")) %>% \r\n  mutate(depth_plot = ifelse(depth_mean >= 250, 250, depth_mean))\r\n\r\n# Glimpse the data \r\nglimpse(Sv_and_depth)\r\n\r\n\r\nRows: 362\r\nColumns: 16\r\n$ Spatial_interval <dbl> 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15...\r\n$ Layer            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...\r\n$ Sv_mean          <dbl> -67.97805, -67.65053, -66.65866, -68.244...\r\n$ Frequency        <dbl> 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, ...\r\n$ Date             <dttm> 2011-06-18, 2011-06-18, 2011-06-18, 201...\r\n$ Time_S           <time> 09:58:47, 09:59:47, 10:00:32, 10:01:12,...\r\n$ Time_E           <time> 09:59:42, 10:00:27, 10:01:07, 10:01:47,...\r\n$ Lat_M            <dbl> 38.29396, 38.29309, 38.29230, 38.29147, ...\r\n$ Lon_M            <dbl> -73.99612, -73.99397, -73.99202, -73.989...\r\n$ Datetime_start   <dttm> 2011-06-18 09:58:47, 2011-06-18 09:59:4...\r\n$ Datetime_end     <dttm> 2011-06-18 09:59:42, 2011-06-18 10:00:2...\r\n$ Distance_between <dbl> 0.0000, 211.7871, 192.3324, 204.8778, 20...\r\n$ Distance_along   <dbl> 0.0000, 211.7871, 404.1196, 608.9974, 81...\r\n$ Time_interval    <Interval> 2011-06-18 09:58:47 UTC--2011-06-18...\r\n$ depth_mean       <dbl> 68.43658, 68.25401, 68.22956, 68.10563, ...\r\n$ depth_plot       <dbl> 68.43658, 68.25401, 68.22956, 68.10563, ...\r\n\r\n\r\n\r\n# Top panel\r\nSv_mean_plot <- ggplot(Sv_and_depth, aes(Distance_along, Sv_mean)) +\r\n  geom_line() +\r\n  labs(y=expression(mean~volume~backscatter~S[v]~(dB))) +\r\n  theme(axis.title.x=element_blank())\r\n\r\n# Bottom panel\r\nbathymetry <- ggplot(Sv_and_depth, aes(Distance_along, depth_plot)) +\r\n  geom_line(size = 0.5) +\r\n  scale_y_reverse() +\r\n  labs(x = \"Distance along trackline (m)\", y = \"Depth (m)\")\r\n\r\n# Display the two panels in one figure\r\nSv_mean_plot / bathymetry\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-21-project-11/project-11_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-21T23:00:56+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-21-project-9/",
    "title": "Project 9",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-21",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\ncandy_data <- read_csv(here::here(\"data\", \"candy_crush.csv\"))\r\n\r\n\r\n\r\n\r\n\r\n# Calculating level difficulty\r\ndifficulty <- candy_data %>%\r\n  group_by(level) %>%\r\n  summarise(attempts = sum(num_attempts), wins = sum(num_success)) %>%\r\n  mutate(p_win = wins / attempts)\r\n\r\ndifficulty\r\n\r\n\r\n# A tibble: 15 x 4\r\n   level attempts  wins  p_win\r\n   <dbl>    <dbl> <dbl>  <dbl>\r\n 1     1     1322   818 0.619 \r\n 2     2     1285   666 0.518 \r\n 3     3     1546   662 0.428 \r\n 4     4     1893   705 0.372 \r\n 5     5     6937   634 0.0914\r\n 6     6     1591   668 0.420 \r\n 7     7     4526   614 0.136 \r\n 8     8    15816   641 0.0405\r\n 9     9     8241   670 0.0813\r\n10    10     3282   617 0.188 \r\n11    11     5575   603 0.108 \r\n12    12     6868   659 0.0960\r\n13    13     1327   686 0.517 \r\n14    14     2772   777 0.280 \r\n15    15    30374  1157 0.0381\r\n\r\n\r\n\r\nggplot(difficulty, aes(level, p_win)) +\r\n  geom_col(width = .7) +\r\n  scale_x_continuous(breaks = c(1:15)) +\r\n  scale_y_continuous(labels = scales::percent)\r\n\r\n\r\n\r\n\r\n\r\n\r\ndifficulty %>%\r\n  ggplot(aes(x = level, y = p_win)) + \r\n    geom_line() + geom_point() +\r\n    scale_x_continuous(breaks = 1:15) +\r\n    scale_y_continuous(label = scales::percent) +\r\n    geom_hline(yintercept = 0.1, linetype = 'dashed')\r\n\r\n\r\n\r\n\r\n\r\n\r\ndifficulty_e <- difficulty %>%\r\n    mutate(error = sqrt(p_win * (1 - p_win) / attempts))\r\n\r\n\r\n\r\n\r\n\r\ndifficulty_e %>%\r\n  ggplot(aes(x = level, y = p_win)) + \r\n    geom_line() + geom_point() +\r\n    scale_x_continuous(breaks = 1:15) +\r\n    scale_y_continuous(label = scales::percent) +\r\n    geom_hline(yintercept = 0.1, linetype = 'dashed') +\r\n    geom_errorbar(aes(ymin = p_win - error, ymax = p_win + error))\r\n\r\n\r\n\r\n\r\nThe probability of completing the episode without losing a single time\r\n\r\n\r\np <- prod(difficulty$p_win)\r\n\r\np\r\n\r\n\r\n[1] 9.447141e-12\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-21-project-9/project-9_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-21T02:29:46+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-3/",
    "title": "Project 3",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\nconfirmed_cases_worldwide <- read_csv(here::here(\"data\", \"confirmed_cases_worldwide.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nggplot(confirmed_cases_worldwide, aes(date, cum_cases )) +\r\n  geom_line() \r\n\r\n\r\n\r\n\r\n\r\n\r\n# Read in datasets/confirmed_cases_china_vs_world.csv\r\nconfirmed_cases_china_vs_world <-  read_csv(here::here(\"data\", \"confirmed_cases_china_vs_world.csv\"))\r\n\r\n# See the result\r\nglimpse(confirmed_cases_china_vs_world)\r\n\r\n\r\nRows: 112\r\nColumns: 4\r\n$ is_china  <chr> \"China\", \"China\", \"China\", \"China\", \"China\", \"C...\r\n$ date      <date> 2020-01-22, 2020-01-23, 2020-01-24, 2020-01-25...\r\n$ cases     <dbl> 548, 95, 277, 486, 669, 802, 2632, 578, 2054, 1...\r\n$ cum_cases <dbl> 548, 643, 920, 1406, 2075, 2877, 5509, 6087, 81...\r\n\r\nggplot(confirmed_cases_china_vs_world, aes(date, cum_cases, color = is_china, group = is_china)) +\r\n  geom_line() +\r\n  ylab(\"Cumulative confirmed cases\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nwho_events <- tribble(\r\n  ~ date, ~ event,\r\n  \"2020-01-30\", \"Global health\\nemergency declared\",\r\n  \"2020-03-11\", \"Pandemic\\ndeclared\",\r\n  \"2020-02-13\", \"China reporting\\nchange\"\r\n) %>%\r\n  mutate(date = as.Date(date))\r\n\r\nggplot(confirmed_cases_china_vs_world) +\r\n  geom_line(aes(date, cum_cases, color = is_china, group = is_china)) +\r\n  ylab(\"Cumulative confirmed cases\") +\r\n  geom_vline(data = who_events, aes(xintercept = date), linetype = 8) +\r\n  geom_text(data = who_events, aes(date, label = event), y = 1e5)\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Filter for China, from Feb 15\r\nchina_after_feb15 <- confirmed_cases_china_vs_world %>%\r\n  filter(date >= as.Date(\"2020-02-15\"), is_china == \"China\")\r\n\r\n# Using china_after_feb15, draw a line plot cum_cases vs. date\r\n# Add a smooth trend line using linear regression, no error bars\r\nggplot(china_after_feb15, aes(date, cum_cases)) +\r\n  geom_line() +\r\n  geom_smooth(method = \"lm\", se = FALSE) +\r\n  ylab(\"Cumulative confirmed cases\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Filter confirmed_cases_china_vs_world for not China\r\nnot_china <- confirmed_cases_china_vs_world %>%\r\n  filter(is_china != \"China\")\r\n\r\n# Using not_china, draw a line plot cum_cases vs. date\r\n# Add a smooth trend line using linear regression, no error bars\r\nplt_not_china_trend_lin <- ggplot(not_china, aes(date, cum_cases)) +\r\n  geom_line() +\r\n  geom_smooth(method = \"lm\", se = FALSE) +\r\n  ylab(\"Cumulative confirmed cases\")\r\n\r\n# See the result\r\nplt_not_china_trend_lin \r\n\r\n\r\n\r\n\r\nFrom the plot above, we can see a straight line does not fit well at all, and the rest of the world is growing much faster than linearly. What if we added a logarithmic scale to the y-axis?\r\n\r\n\r\nplt_not_china_trend_lin + \r\n  scale_y_log10()\r\n\r\n\r\n\r\n\r\n\r\n\r\nconfirmed_cases_by_country <- read_csv(here::here(\"data\", \"confirmed_cases_by_country.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nconfirmed_cases_by_country %>% \r\n  group_by(country) %>% \r\n  summarize(total_cases = sum(cum_cases)) %>% \r\n  arrange(desc(total_cases)) %>% \r\n  head(7) -> top_countries_by_total_cases\r\n\r\n\r\n\r\n\r\n\r\nconfirmed_cases_top7_outside_china <- read_csv(here::here(\"data\", \"confirmed_cases_top7_outside_china.csv\")) \r\n\r\nggplot(confirmed_cases_top7_outside_china, aes(date, cum_cases, color = country)) +\r\n  geom_line() +\r\n  ylab(\"Cumulative confirmed cases\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-3/project-3_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-12-20T03:26:13+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-4/",
    "title": "Project 4",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\nlibrary(magrittr)\r\nlibrary(forecast)\r\n\r\n\r\n\r\n\r\n\r\nirish_potatoes <- read_csv(\r\n  here::here(\"data\", \"Potatoes_Irish.csv\"),\r\n  col_types = cols_only(\r\n    adm1_name = col_character(),\r\n    mkt_name = col_character(),\r\n    cm_name = col_character(),\r\n    mp_month = col_integer(),\r\n    mp_year = col_integer(),\r\n    mp_price = col_double()\r\n  )\r\n) %>% \r\n    rename(\r\n    region = adm1_name, \r\n    market = mkt_name,\r\n    commodity_kg = cm_name,\r\n    month = mp_month,\r\n    year = mp_year,\r\n    price_rwf = mp_price\r\n  )\r\n\r\n\r\n\r\n\r\n\r\nirish_potatoes %>% \r\n  mutate(date = ymd(paste(year, month, \"01\", sep = \"-\"))) %>% \r\n  select(-month, -year) -> potatoes_cleaned\r\n\r\n\r\n\r\n\r\n\r\nread_price_data <- function (commodity) {\r\n  irish_potatoes <- read_csv(\r\n  here::here(\"data\", paste0(commodity, \".csv\")),\r\n  col_types = cols_only(\r\n    adm1_name = col_character(),\r\n    mkt_name = col_character(),\r\n    cm_name = col_character(),\r\n    mp_month = col_integer(),\r\n    mp_year = col_integer(),\r\n    mp_price = col_double()\r\n  )\r\n) %>% \r\n    rename(\r\n    region = adm1_name, \r\n    market = mkt_name,\r\n    commodity_kg = cm_name,\r\n    month = mp_month,\r\n    year = mp_year,\r\n    price_rwf = mp_price\r\n  )\r\n  \r\n  irish_potatoes %>% \r\n  mutate(date = ymd(paste(year, month, \"01\", sep = \"-\"))) %>% \r\n  select(-month, -year) -> potatoes_cleaned\r\n}\r\n\r\n\r\n\r\n\r\n\r\nbeans_dry <- read_price_data(\"Beans (dry)\")\r\n\r\n\r\n\r\n\r\n\r\nprice_vs_time_plot <- function (prices, commodity) {\r\n  ggplot(potatoes_cleaned, aes(date, price_rwf, group = market)) +\r\n    geom_line(alpha = 0.2) +\r\n    ggtitle(paste0(commodity, \" price over time\"))\r\n}\r\n\r\n\r\n\r\n\r\n\r\nprice_vs_time_plot(beans_dry, \"Beans\")\r\n\r\n\r\n\r\n\r\n\r\n\r\npotato_prices_summarized <- potatoes_cleaned %>%\r\n    group_by(date) %>%\r\n    summarize(median_price_rwf = median(price_rwf))\r\n\r\n\r\n\r\n\r\n\r\npotato_time_series <- potato_prices_summarized %$% \r\n  ts(\r\n    median_price_rwf, \r\n    start = c(year(min(date)), month(min(date))), \r\n    end   = c(year(max(date)), month(max(date))), \r\n    frequency = 12\r\n  )\r\n\r\npotato_time_series\r\n\r\n\r\n          Jan      Feb      Mar      Apr      May      Jun      Jul\r\n2008  97.5000 100.0000  95.0000  96.2500  95.0000 110.0000 116.6667\r\n2009 120.0000 122.5000 130.0000 131.2500 135.0000 124.3125 125.8333\r\n2010 109.6875 113.5000 131.2500 132.0833 140.4167 147.3750 142.5000\r\n2011 105.7000 108.1750 118.8750 145.0143 148.6667 148.0500 137.4048\r\n2012 150.7500 175.2500 186.0139 186.2500 182.5000 162.7500 179.1250\r\n2013 154.3333 157.0000 171.2500 187.5000 177.0000 202.2500 210.0000\r\n2014 138.3333 158.7500 186.2500 198.2500 191.0000 189.3333 182.5000\r\n2015 136.2500 157.6071 178.0000 190.2778 179.3750 168.3333 180.0000\r\n          Aug      Sep      Oct      Nov      Dec\r\n2008 125.0000 136.2500 130.0000 127.5000 114.3750\r\n2009 144.2500 181.2500 170.0000 150.2500 112.0000\r\n2010 161.5000 182.4000 162.5000 151.5000 122.5000\r\n2011 137.2619 141.6667 144.2000 133.1750 141.5000\r\n2012 196.9643 226.5000 203.5000 169.2500 144.0000\r\n2013 233.1875 241.3333 237.5000 176.7083 140.0000\r\n2014 187.6191 200.0000 183.1309 150.0000 133.9286\r\n2015 202.1250 223.5000 217.5000 216.1250 190.0000\r\n\r\n\r\n\r\ncreate_price_time_series <- function(prices) {\r\n  potato_prices_summarized <- prices %>%\r\n    group_by(date) %>%\r\n    summarize(median_price_rwf = median(price_rwf))\r\n  \r\n  potato_time_series <- potato_prices_summarized %$% \r\n    ts(\r\n      median_price_rwf, \r\n      start = c(year(min(date)), month(min(date))), \r\n      end   = c(year(max(date)), month(max(date))), \r\n      frequency = 12\r\n    )\r\n  \r\n  potato_time_series\r\n}\r\n\r\n\r\n\r\n\r\n\r\ncreate_price_time_series(beans_dry)\r\n\r\n\r\n          Jan      Feb      Mar      Apr      May      Jun      Jul\r\n2008 270.0000 250.0000 265.0000 275.0000 288.7500 292.5000 333.3333\r\n2009 260.0000 254.3750 245.0000 250.0000 220.0000 234.1875 248.5000\r\n2010 256.0000 250.0000 251.5000 262.5000 275.4167 263.4583 279.9375\r\n2011 271.6250 250.0000 273.9000 303.3095 331.9000 309.3250 307.3500\r\n2012 265.0000 272.3333 296.6528 333.3333 346.6667 334.4285 317.5000\r\n2013 286.0000 293.5000 328.3750 352.5000 368.7679 371.3958 375.4750\r\n2014 345.5000 365.0000 392.2500 400.0000 384.1667 400.0000 400.0000\r\n2015 301.0000 305.0000 326.6667 391.3333 418.5000 400.0000 370.0000\r\n          Aug      Sep      Oct      Nov      Dec\r\n2008 370.0000 383.7500 377.5000 337.5000 300.0000\r\n2009 270.0000 326.6667 350.0000 381.7500 384.1667\r\n2010 293.5000 327.5000 326.0000 317.3974 306.3654\r\n2011 321.1667 329.9583 316.0000 310.5625 300.0000\r\n2012 333.8095 345.0000 350.0000 350.0000 345.7321\r\n2013 384.7250 472.3333 522.0000 524.5000 450.0000\r\n2014 403.2500 410.2500 391.0000 366.6667 344.8000\r\n2015 380.2500 396.6000 414.5417 448.2500 466.3750\r\n\r\n\r\n\r\npotato_price_forcast <- forecast(potato_time_series)\r\n\r\nautoplot(potato_price_forcast, main = \"Potato price forecast\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nbeans_time_series <- create_price_time_series(beans_dry)\r\n\r\nplot_price_forecast <- function(time_series, commodity) {\r\n  potato_price_forcast <- forecast(time_series)\r\n  autoplot(potato_price_forcast, main = paste0(commodity, \" price forecast\"))\r\n}\r\n\r\nplot_price_forecast(beans_time_series, \"Beans\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Choose dry beans as the commodity\r\ncommodity <- \"Peas+(fresh)\"\r\n\r\n# Read the price data\r\nbean_prices <- read_price_data(commodity)\r\n\r\n# Plot price vs. time\r\nprice_vs_time_plot(bean_prices, commodity)\r\n\r\n\r\n\r\n# Create a price time series\r\nbean_time_series <- create_price_time_series(bean_prices)\r\n\r\n# Plot the price forecast\r\nplot_price_forecast(bean_time_series, commodity)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-4/project-4_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2020-12-21T01:45:34+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-5/",
    "title": "Project 5",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\n\r\nby_tag_year <- read_csv(here::here(\"data\", \"by_tag_year.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nby_tag_year_fraction <- by_tag_year %>% \r\n  mutate(fraction = number / year_total)\r\n\r\n\r\n\r\n\r\n\r\nby_tag_year_fraction %>% \r\n  filter(tag == \"r\")  -> r_over_time\r\n\r\n\r\n\r\n\r\n\r\nggplot(r_over_time, aes(year, fraction)) +\r\n    geom_line()\r\n\r\n\r\n\r\n\r\n\r\n\r\nselected_tags <- c(\"r\", \"dplyr\", \"ggplot2\")\r\n\r\nselected_tags_over_time <- r_over_time <- by_tag_year_fraction %>% \r\n  filter(tag %in% selected_tags)\r\n\r\nggplot(selected_tags_over_time, aes(year, fraction, color = tag)) +\r\n    geom_line()\r\n\r\n\r\n\r\n\r\n\r\n\r\nsorted_tags <- by_tag_year %>%\r\n    group_by(tag) %>%\r\n    summarise(n = sum(number)) %>%\r\n    arrange(desc(n))\r\n\r\n\r\n\r\n\r\n\r\nhighest_tags <- head(sorted_tags$tag)\r\n\r\nby_tag_subset <- by_tag_year_fraction %>%\r\n    filter(tag %in% highest_tags)\r\n\r\n# Plot tags over time on a line plot using color to represent tag\r\nggplot(by_tag_subset, aes(x = year,\r\n                          y = fraction,\r\n                          color = tag)) +\r\n  geom_line(size = 1)\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Get tags of interest\r\nmy_tags <- c(\"android\", \"ios\", \"windows-phone\")\r\n\r\n# Filter for those tags\r\nby_tag_subset <- selected_tags_over_time <- by_tag_year_fraction %>%\r\n  filter(tag %in% my_tags)\r\n\r\n# Plot tags over time on a line plot using color to represent tag\r\nggplot(by_tag_subset, aes(x = year,\r\n                          y = fraction,\r\n                          color = tag)) +\r\n  geom_line(size = 1)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-5/project-5_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-12-20T17:32:04+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-6/",
    "title": "Project 6",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\n\r\nyearly <- read_csv(here::here(\"data\", \"yearly_deaths_by_clinic.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nyearly %>% \r\n  mutate(proportion_deaths = deaths / births) -> yearly\r\n\r\n\r\n\r\n\r\n\r\nggplot(yearly, aes(year, proportion_deaths, color = clinic)) +\r\n  geom_line()\r\n\r\n\r\n\r\n\r\n\r\n\r\nmonthly <- read_csv(here::here(\"data\", \"monthly_deaths.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nmonthly  <- monthly %>%\r\n    mutate(proportion_deaths = deaths / births)\r\nhead(monthly)\r\n\r\n\r\n# A tibble: 6 x 4\r\n  date       births deaths proportion_deaths\r\n  <date>      <dbl>  <dbl>             <dbl>\r\n1 1841-01-01    254     37           0.146  \r\n2 1841-02-01    239     18           0.0753 \r\n3 1841-03-01    277     12           0.0433 \r\n4 1841-04-01    255      4           0.0157 \r\n5 1841-05-01    255      2           0.00784\r\n6 1841-06-01    200     10           0.05   \r\n\r\n\r\n\r\nggplot(monthly, aes(date, proportion_deaths)) +\r\n  geom_line() + \r\n  labs(\r\n    x = \"Date\",\r\n    y = \"Proportion of deaths\"\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\nhandwashing_start = as.Date('1847-06-01')\r\n\r\nmonthly <- monthly %>% \r\n  mutate(handwashing_started = if_else(date < handwashing_start, FALSE, TRUE))\r\n\r\n\r\n\r\n\r\n\r\nggplot(monthly, aes(date, proportion_deaths, color = handwashing_started)) +\r\n  geom_line() + \r\n  labs(\r\n    x = \"Date\",\r\n    y = \"Proportion of deaths\"\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\nmonthly_summary <- monthly %>% \r\n  group_by(handwashing_started) %>% \r\n  summarise(mean(proportion_deaths))\r\n\r\n\r\n\r\n\r\n\r\nboxplot(proportion_deaths ~ handwashing_started, data = monthly)\r\n\r\n\r\n\r\n\r\n\r\n\r\nt.test(proportion_deaths ~ handwashing_started, data = monthly)\r\n\r\n\r\n\r\n    Welch Two Sample t-test\r\n\r\ndata:  proportion_deaths by handwashing_started\r\nt = 9.6101, df = 92.435, p-value = 1.445e-15\r\nalternative hypothesis: true difference in means is not equal to 0\r\n95 percent confidence interval:\r\n 0.06660662 0.10130659\r\nsample estimates:\r\nmean in group FALSE  mean in group TRUE \r\n         0.10504998          0.02109338 \r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-6/project-6_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-20T19:57:58+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-7/",
    "title": "Project 7",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\nnobel <- read_csv(here::here(\"data\", \"nobel.csv\"))\r\n\r\n\r\n\r\n\r\n\r\nnobel %>% \r\n  count()\r\n\r\n\r\n# A tibble: 1 x 1\r\n      n\r\n  <int>\r\n1   911\r\n\r\n\r\n\r\nnobel %>% \r\n  count(sex)\r\n\r\n\r\n# A tibble: 3 x 2\r\n  sex        n\r\n  <chr>  <int>\r\n1 Female    49\r\n2 Male     836\r\n3 <NA>      26\r\n\r\n\r\n\r\nnobel %>% \r\n  count(birth_country) %>% \r\n  arrange(-n) %>% \r\n  head(20)\r\n\r\n\r\n# A tibble: 20 x 2\r\n   birth_country                n\r\n   <chr>                    <int>\r\n 1 United States of America   259\r\n 2 United Kingdom              85\r\n 3 Germany                     61\r\n 4 France                      51\r\n 5 Sweden                      29\r\n 6 <NA>                        26\r\n 7 Japan                       24\r\n 8 Canada                      18\r\n 9 Netherlands                 18\r\n10 Italy                       17\r\n11 Russia                      17\r\n12 Switzerland                 16\r\n13 Austria                     14\r\n14 Norway                      12\r\n15 China                       11\r\n16 Denmark                     11\r\n17 Australia                   10\r\n18 Belgium                      9\r\n19 Scotland                     9\r\n20 South Africa                 9\r\n\r\n\r\n\r\nprop_usa_winners <- nobel %>% \r\n    mutate(usa_born_winner = if_else(birth_country == \"United States of America\", TRUE, FALSE))\r\n\r\n\r\n\r\n\r\n\r\nprop_usa_winners <- nobel %>% \r\n  mutate(usa_born_winner = if_else(birth_country == \"United States of America\", TRUE, FALSE)) %>% \r\n  mutate(decade = round(year / 10) * 10) %>% \r\n  group_by(decade) %>%\r\n  summarise(proportion = sum(usa_born_winner, na.rm = TRUE) /n())\r\n\r\n\r\n\r\n\r\n\r\nggplot(prop_usa_winners, aes(decade, proportion)) +\r\n  geom_point() +\r\n  geom_line() +\r\n  scale_y_continuous(labels = scales::percent, limits = c(0, 1))\r\n\r\n\r\n\r\n\r\n\r\n\r\nprop_female_winners <- nobel %>% \r\n  mutate(female_winner = sex == \"Female\") %>% \r\n  mutate(decade = round(year / 10) * 10) %>% \r\n  group_by(decade, category) %>% \r\n  summarise(proportion = mean(female_winner, na.rm = TRUE))\r\n\r\nggplot(prop_female_winners, aes(decade, proportion, color = category)) +\r\n  geom_point() +\r\n  geom_line() +\r\n  scale_y_continuous(labels = scales::percent, limits = c(0, 1))\r\n\r\n\r\n\r\n\r\n\r\n\r\nnobel %>% \r\n  filter(sex == \"Female\") %>% \r\n  top_n(1, desc(year))\r\n\r\n\r\n# A tibble: 1 x 18\r\n   year category prize motivation prize_share laureate_id\r\n  <dbl> <chr>    <chr> <chr>      <chr>             <dbl>\r\n1  1903 Physics  The ~ \"\\\"in rec~ 1/4                   6\r\n# ... with 12 more variables: laureate_type <chr>, full_name <chr>,\r\n#   birth_date <date>, birth_city <chr>, birth_country <chr>,\r\n#   sex <chr>, organization_name <chr>, organization_city <chr>,\r\n#   organization_country <chr>, death_date <date>, death_city <chr>,\r\n#   death_country <chr>\r\n\r\n\r\n\r\nlibrary(magrittr)\r\nmore_than_one <- nobel %>% \r\n  count(full_name) %>% \r\n  filter(n > 1) %>% \r\n  pull(full_name)\r\n\r\n\r\n\r\n\r\n\r\nnobel_age <- nobel %>% \r\n  mutate(age = year - year(birth_date))\r\n\r\n\r\n\r\n\r\n\r\nggplot(nobel_age, aes(year, age)) + \r\n    geom_point() + geom_smooth() +\r\n    scale_y_continuous(breaks = seq(10, 100, 20))\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(nobel_age, aes(year, age)) + \r\n  geom_smooth() +\r\n  scale_y_continuous(breaks = seq(10, 100, 20)) +\r\n  facet_wrap(~ category)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-7/project-7_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2020-12-20T22:43:38+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-20-project-8/",
    "title": "Project 8",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-20",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\n\r\n\r\nresponses <- read_csv(here::here(\"data\", \"kagglesurvey.csv\"))\r\n\r\n\r\n\r\n\r\n\r\ntools <- responses %>% \r\n  mutate(work_tools = str_split(WorkToolsSelect, \",\")) %>% \r\n  unnest(work_tools) \r\n\r\nhead(tools)\r\n\r\n\r\n# A tibble: 6 x 6\r\n  Respondent WorkToolsSelect LanguageRecomme~ EmployerIndustry\r\n       <dbl> <chr>           <chr>            <chr>           \r\n1          1 Amazon Web ser~ F#               Internet-based  \r\n2          1 Amazon Web ser~ F#               Internet-based  \r\n3          1 Amazon Web ser~ F#               Internet-based  \r\n4          2 Amazon Machine~ Python           Mix of fields   \r\n5          2 Amazon Machine~ Python           Mix of fields   \r\n6          2 Amazon Machine~ Python           Mix of fields   \r\n# ... with 2 more variables: WorkAlgorithmsSelect <chr>,\r\n#   work_tools <chr>\r\n\r\n\r\n\r\ntool_count <- tools %>% \r\n  group_by(work_tools) %>% \r\n  summarise(n = n()) %>% \r\n  arrange(-n)\r\n\r\nhead(tool_count)\r\n\r\n\r\n# A tibble: 6 x 2\r\n  work_tools            n\r\n  <chr>             <int>\r\n1 Python             6073\r\n2 R                  4708\r\n3 SQL                4261\r\n4 Jupyter notebooks  3206\r\n5 TensorFlow         2256\r\n6 <NA>               2198\r\n\r\n\r\n\r\nggplot(tool_count, aes(fct_reorder(work_tools, n), n)) +\r\n  geom_bar(stat = \"identity\") +\r\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\r\n\r\n\r\n\r\n\r\n\r\n\r\ndebate_tools <- responses  %>% \r\n  mutate(language_preference = case_when(\r\n    str_detect(WorkToolsSelect, \"R\") & ! str_detect(WorkToolsSelect, \"Python\") ~ \"R\",\r\n    str_detect(WorkToolsSelect, \"Python\") & ! str_detect(WorkToolsSelect, \"R\") ~ \"Python\",\r\n    str_detect(WorkToolsSelect, \"R\") & str_detect(WorkToolsSelect, \"Python\")   ~ \"both\",\r\n    TRUE ~ \"neither\"\r\n  ))\r\n\r\n\r\n\r\n\r\n\r\n# Group by language preference, calculate number of responses, and remove \"neither\"\r\ndebate_plot <- debate_tools  %>% \r\n   group_by(language_preference)  %>% \r\n   summarise(n = n()) %>% \r\n  filter(language_preference != \"neither\")\r\n\r\n\r\n\r\n\r\n\r\nggplot(debate_plot, aes(language_preference, n)) +\r\n  geom_bar(stat = \"identity\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nrecommendations <- debate_tools  %>% \r\n    group_by(language_preference, LanguageRecommendationSelect)  %>%\r\n    summarise(count = n())  %>% \r\n    arrange(language_preference, desc(count))  %>% \r\n    mutate(row = row_number()) %>% \r\n    filter(row <= 4)\r\n\r\n\r\n\r\n\r\n\r\nggplot(recommendations, aes(x = LanguageRecommendationSelect, y = count)) +\r\n    geom_bar(stat = \"identity\") + \r\n    facet_wrap(~language_preference)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-20-project-8/project-8_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2020-12-21T00:00:15+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-19-project-1/",
    "title": "Project 1",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-19",
    "categories": [],
    "contents": "\r\nLibraries:\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\n\r\nlife_expec <- read_csv(here::here(\"data\", \"undata1.csv\")) %>% \r\n  janitor::clean_names()\r\n\r\n\r\n\r\n\r\n\r\n(dt <- life_expec %>% \r\n  filter(year == \"2000-2005\") %>% \r\n  rename(country = country_or_area, gender = subgroup, life_expectancy = value) %>% \r\n  select(country, gender, life_expectancy) %>% \r\n  pivot_wider(names_from = gender, values_from = life_expectancy)   \r\n)\r\n\r\n\r\n# A tibble: 195 x 3\r\n   country     Female  Male\r\n   <chr>        <dbl> <dbl>\r\n 1 Afghanistan     42    42\r\n 2 Albania         79    73\r\n 3 Algeria         72    70\r\n 4 Angola          43    39\r\n 5 Argentina       78    71\r\n 6 Armenia         75    68\r\n 7 Aruba           76    70\r\n 8 Australia       83    78\r\n 9 Austria         82    76\r\n10 Azerbaijan      70    63\r\n# ... with 185 more rows\r\n\r\n\r\n\r\ndt %>% \r\n  ggplot(aes(x = Male, y = Female)) +\r\n  geom_point() +\r\n  xlim(35, 85) +\r\n  ylim(35, 85) + \r\n  geom_abline(slope = 1)\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(dt, aes(x=Male, y=Female))+\r\n  geom_point(colour=\"white\", fill=\"chartreuse3\", shape=21, alpha=.55, size=5)+\r\n  geom_abline(intercept = 0, slope = 1, linetype=2)+\r\n  scale_x_continuous(limits=c(35,85))+\r\n  scale_y_continuous(limits=c(35,85))+\r\n  labs(title=\"Life Expectancy at Birth by Country\",\r\n       subtitle=\"Years. Period: 2000-2005. Average.\",\r\n       caption=\"Source: United Nations Statistics Division\",\r\n       x=\"Males\",\r\n       y=\"Females\")\r\n\r\n\r\n\r\n\r\nFinding where Male and Female life expectancy difference is the highest.\r\n\r\n\r\ntop_male <- dt %>% arrange(desc(Male - Female)) %>% head(3)\r\ntop_female <- dt %>% arrange(desc(Female - Male)) %>% head(3)\r\n\r\n\r\n\r\n\r\n\r\nggplot(dt, aes(x=Male, y=Female))+\r\n  geom_point(colour=\"white\", fill=\"chartreuse3\", shape=21, alpha=.55, size=5)+\r\n  geom_abline(intercept = 0, slope = 1, linetype=2)+\r\n  scale_x_continuous(limits=c(35,85))+\r\n  scale_y_continuous(limits=c(35,85))+\r\n  geom_text(data = top_male, aes(label = country)) +\r\n  geom_text(data = top_female, aes(label = country)) +\r\n  labs(title=\"Life Expectancy at Birth by Country\",\r\n       subtitle=\"Years. Period: 2000-2005. Average.\",\r\n       caption=\"Source: United Nations Statistics Division\",\r\n       x=\"Males\",\r\n       y=\"Females\") +\r\n  theme_bw()\r\n\r\n\r\n\r\n\r\n\r\n\r\nlife_expec %>% \r\n  filter(year %in% c(\"1985-1990\", \"2000-2005\")) %>% \r\n  mutate(sub_year = paste(subgroup, year, sep = \"_\")) %>% \r\n  mutate(sub_year=gsub(\"-\", \"_\", sub_year)) %>% \r\n  select(-subgroup, -year) %>% \r\n  pivot_wider(names_from = sub_year, values_from = value) %>% \r\n  mutate(\r\n    diff_female = Female_2000_2005 - Female_1985_1990,\r\n    diff_male = Male_2000_2005 - Male_1985_1990 \r\n  ) -> dt2\r\n\r\n\r\n\r\n\r\n\r\nggplot(dt2, aes(x=diff_male, y=diff_female, label=country_or_area))+\r\n  geom_point(colour=\"white\", fill=\"chartreuse3\", shape=21, alpha=.55, size=5)+\r\n  geom_abline(intercept = 0, slope = 1, linetype=2)+\r\n  xlim(-25, 25) +\r\n  ylim(-25, 25) +\r\n  geom_hline(yintercept = 0) +\r\n  geom_vline(xintercept = 0) +\r\n  labs(title=\"Life Expectancy at Birth by Country in Years\",\r\n       subtitle=\"Difference between 1985-1990 and 2000-2005. Average.\",\r\n       caption=\"Source: United Nations Statistics Division\",\r\n       x=\"Males\",\r\n       y=\"Females\")+\r\ntheme_bw()\r\n\r\n\r\n\r\n\r\n\r\n\r\ntop <- dt2 %>% arrange(diff_male+diff_female) %>% head(3)\r\nbottom <- dt2 %>% arrange(-(diff_male+diff_female)) %>% head(3)\r\n\r\nggplot(dt2, aes(x=diff_male, y=diff_female, label=country_or_area))+\r\n  geom_point(colour=\"white\", fill=\"chartreuse3\", shape=21, alpha=.55, size=5)+\r\n  geom_abline(intercept = 0, slope = 1, linetype=2)+\r\n  geom_text(data = top, aes(label = country_or_area)) +\r\n  geom_text(data = bottom, aes(label = country_or_area)) +\r\n  xlim(-25, 25) +\r\n  ylim(-25, 25) +\r\n  geom_hline(yintercept = 0) +\r\n  geom_vline(xintercept = 0) +\r\n  labs(title=\"Life Expectancy at Birth by Country in Years\",\r\n       subtitle=\"Difference between 1985-1990 and 2000-2005. Average.\",\r\n       caption=\"Source: United Nations Statistics Division\",\r\n       x=\"Males\",\r\n       y=\"Females\")+\r\ntheme_bw()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-19-project-1/project-1_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-20T01:55:26+06:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-19-project-2/",
    "title": "Project 2",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Sajib Devnath",
        "url": "https://www.sajibdevnath.com"
      }
    ],
    "date": "2020-12-19",
    "categories": [],
    "contents": "\r\nWho Is Drunk and When in Ames, Iowa?\r\nLibrary:\r\n\r\n\r\nlibrary(tidyverse)\r\ntheme_set(theme_minimal())\r\n\r\n\r\n\r\nData:\r\n\r\n\r\nba_data <- read_csv(here::here(\"data\", \"breath_alcohol_ames.csv\"))\r\nba_year <- count(ba_data, year)\r\n\r\n\r\n\r\nData manipulation:\r\n\r\n\r\n(\r\n  \r\n  pds <- ba_data %>% \r\n    group_by(location) %>% \r\n    summarise(n = n())\r\n  \r\n)\r\n\r\n\r\n# A tibble: 2 x 2\r\n  location     n\r\n  <chr>    <int>\r\n1 Ames PD    616\r\n2 ISU PD     940\r\n\r\nHourly Breathalyzer tests:\r\n\r\n\r\nba_data %>% \r\n  group_by(hour) %>% \r\n  summarise(test_num = n()) %>% \r\n  ggplot(aes(x = hour, y = test_num)) +\r\n  geom_col()\r\n\r\n\r\n\r\n\r\nMonthly Breathalyzer tests:\r\n\r\n\r\nba_data %>% \r\n  group_by(month) %>% \r\n  summarise(test_num = n()) %>% \r\n  ggplot(aes(x = month, y = test_num)) +\r\n  geom_col(width = .7) +\r\n  scale_x_continuous(breaks = 1:12)\r\n\r\n\r\n\r\n\r\nTests by Gender:\r\n\r\n\r\nba_data %>% \r\n  filter(!is.na(gender)) %>% \r\n  mutate(meanRes = (Res1 + Res2) / 2) %>% \r\n  ggplot(aes(gender, meanRes)) +\r\n  geom_boxplot()\r\n\r\n\r\n\r\n\r\n\r\n\r\nba_data %>% \r\n  mutate(date = lubridate::ymd(paste(year, month, day, sep = \"-\"))) %>% \r\n  mutate(week = lubridate::week(date)) %>% \r\n  mutate(year = as.factor(year)) %>% \r\n  count(year, week) %>% \r\n  ggplot(aes(week, n, color = year)) +\r\n  geom_line() +\r\n  facet_wrap(~ year, ncol = 1, strip.position = \"right\") +\r\n  scale_x_continuous(breaks = seq(0,52,4))\r\n\r\n\r\n\r\n\r\n\r\n\r\nweekly <- ba_data %>% \r\n  mutate(date = lubridate::ymd(paste(year, month, day, sep = \"-\"))) %>% \r\n  mutate(week = lubridate::week(date)) %>% \r\n  mutate(year = as.factor(year)) %>% \r\n  count(year, week) \r\n\r\nggplot() + \r\n  geom_point(data = weekly, aes(x = week, y = n, color = year)) + \r\n  geom_line(data = weekly, aes(x = week, y = n, color = year)) +  # included to make the plot more readable \r\n  geom_segment(data = NULL, arrow = arrow(angle = 20, length = unit(0.1, \"inches\"),\r\n                                          ends = \"last\", type = \"closed\"), \r\n               aes(x = c(20,20), xend = c(15.5,16), y = c(21, 20), yend = c(21, 12.25))) + \r\n  geom_text(data = NULL, aes(x = 23, y = 20.5, label = \"VEISHEA Weeks\"), size = 3) + \r\n  scale_x_continuous(breaks = seq(0,52,4)) +\r\n  theme(aspect.ratio = .5)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-19-project-2/project-2_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2020-12-20T02:31:54+06:00",
    "input_file": {}
  }
]
